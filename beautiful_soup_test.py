# =============================================================================
# Beautiful Soup
# =============================================================================
import requests
from bs4 import BeautifulSoup

# =============================================================================
# Part 1
# =============================================================================

# result = requests.get('https://www.google.com')
# src = result.content
# soup = BeautifulSoup(src,'lxml')
# links = soup.find_all("a")
# #print(links)
# for link in links:
#     if "Ã€ propos" in link.text:
#         print(link)
#         print(link.attrs['href'])

# =============================================================================
# Part 2
# =============================================================================

# =============================================================================
# result = requests.get('https://www.whitehouse.gov/briefings-statements/')
# src = result.content
# soup = BeautifulSoup(src,'lxml')
# 
# urls = []
# for title in soup.find_all("h2"):
#     a_tag = title.find("a")
#     urls.append(a_tag.attrs['href'])
# =============================================================================
    
# =============================================================================
# Part 3
# =============================================================================

